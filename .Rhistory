{
shortest_paths(starwars_char, .[1], .[2], 'out', output = 'both')
}
V(starwars_char)$inDiam <- V(starwars_char) %in% sp$vpath[[1]]
E(starwars_char)$inDiam <- E(starwars_char) %in% sp$epath[[1]]
set.seed(1234)
ggraph(starwars_char, layout = 'drl' ) +
geom_edge_link(aes(colour = inDiam,
edge_width = inDiam),
alpha = .5) +
geom_node_point(aes(fill = inDiam), size = 4, shape = 21) +
theme_void() +
scale_edge_colour_manual(values = c('lightgrey', 'black')) +
scale_edge_width_manual(values = c(.5, 2)) +
theme(legend.position = 'none')
sp <- starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices %>%
{
shortest_paths(starwars_char, .[1], .[2], 'out', output = 'both')
}
V(starwars_char)$inDiam <- V(starwars_char) %in% sp$vpath[[1]]
E(starwars_char)$inDiam <- E(starwars_char) %in% sp$epath[[1]]
set.seed(1234)
ggraph(starwars_char, layout = 'drl' ) +
geom_edge_link(aes(colour = inDiam,
edge_width = inDiam),
alpha = .25) +
geom_node_point(aes(fill = inDiam), size = 4, shape = 21) +
theme_void() +
scale_edge_colour_manual(values = c('lightgrey', 'black')) +
scale_edge_width_manual(values = c(.5, 2)) +
theme(legend.position = 'none')
sp <- starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices %>%
{
shortest_paths(starwars_char, .[1], .[2], 'out', output = 'both')
}
V(starwars_char)$inDiam <- V(starwars_char) %in% sp$vpath[[1]]
V(starwars_char)$longLabel <- ifelse(V(starwars_char)$inDiam, V(starwars_char)$name, NA)
E(starwars_char)$inDiam <- E(starwars_char) %in% sp$epath[[1]]
set.seed(1234)
ggraph(starwars_char, layout = 'drl' ) +
geom_edge_link(aes(colour = inDiam,
edge_width = inDiam),
alpha = .25) +
geom_node_point(aes(fill = inDiam), size = 4, shape = 21) +
geom_node_text(label)
theme_void() +
scale_edge_colour_manual(values = c('lightgrey', 'black')) +
scale_edge_width_manual(values = c(.5, 2)) +
theme(legend.position = 'none')
V(starwars_char)$longLabel
sp <- starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices %>%
{
shortest_paths(starwars_char, .[1], .[2], 'out', output = 'both')
}
V(starwars_char)$inDiam <- V(starwars_char) %in% sp$vpath[[1]]
V(starwars_char)$longLabel <- ifelse(V(starwars_char)$inDiam, V(starwars_char)$name, NA)
E(starwars_char)$inDiam <- E(starwars_char) %in% sp$epath[[1]]
set.seed(1234)
ggraph(starwars_char, layout = 'drl' ) +
geom_edge_link(aes(colour = inDiam,
edge_width = inDiam),
alpha = .25) +
geom_node_point(aes(fill = inDiam), size = 4, shape = 21) +
geom_node_text(aes(label = longLabel))+
theme_void() +
scale_edge_colour_manual(values = c('lightgrey', 'black')) +
scale_edge_width_manual(values = c(.5, 2)) +
theme(legend.position = 'none')
sp <- starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices %>%
{
shortest_paths(starwars_char, .[1], .[2], 'out', output = 'both')
}
V(starwars_char)$inDiam <- V(starwars_char) %in% sp$vpath[[1]]
V(starwars_char)$longLabel <- ifelse(V(starwars_char)$inDiam, V(starwars_char)$name %>% str_replace('character:', ''), NA)
E(starwars_char)$inDiam <- E(starwars_char) %in% sp$epath[[1]]
set.seed(1234)
ggraph(starwars_char, layout = 'drl' ) +
geom_edge_link(aes(colour = inDiam,
edge_width = inDiam),
alpha = .25) +
geom_node_point(aes(fill = inDiam), size = 4, shape = 21) +
geom_node_text(aes(label = longLabel))+
theme_void() +
scale_edge_colour_manual(values = c('lightgrey', 'black')) +
scale_edge_width_manual(values = c(.5, 2)) +
theme(legend.position = 'none')
closeness(starwars_char)
#![](part_3_images/UKfaculty_closeness.png)
V(starwars_char)$cls <- closeness(starwars_char)
V(starwars_char)$cls_color <- V(starwars_char)$cls  %>%
sapply(function(x){
pct <- (length(.)-5)/length(.)
pct <- quantile(., pct)
x >= pct
})
set.seed(1234)
ggraph(starwars_char, layout = 'drl' ) +
geom_edge_link(colour = 'lightgrey') +
geom_node_point(aes(fill = cls_color,
size = cls), shape = 21) +
theme_void() +
theme(legend.position = 'none')
starwars_char %>%
closeness(., directed = F) %>%
sort(decreasing = T) %>%
head
starwars_char %>%
closeness(., mode = 'all') %>%
sort(decreasing = T) %>%
head
UKfaculty
data(UKFaculty)
data(UKfaculty)
sp
starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices
starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices
starwars_char %>%
farthest_vertices(weights = NA) %>%
.$vertices %>%
{
shortest_paths(starwars_char, .[1], .[2], 'out', output = 'both')
}
library(igraphdata)
data(UKfaculty)
UKfaculty
eigen_centrality(UKfaculty, directed = T)$vector %>%
sort(decreasing = T)
eigen_centrality(UKfaculty, directed = T)$vector
example_text <- "Graphs are an awesome data structure. You can store your data in a graph to optimize data queries. You can also create recommendation systems with graphs."
example_text %>%
str_split('.')
example_text
str_split(example_text, '.')
str_split(example_text, '\\.')
library(tidyverse)
library(tidytext)
library(igraph)
example_text %>%
str_split('\\.') %>%
unlist() %>%
str_trim()
tidytext::unnest_tokens(example_text)
library(tidyverse)
library(tidytext)
library(igraph)
text_df <- example_text %>%
str_split('\\.') %>%
unlist() %>%
str_trim() %>%
str_to_lower() %>%
str_split(' ') %>%
map(function(x){
tibble(from = x[1:(nrow(x)-1)],
to = x[2:nrow(x)],
next_id = n())
})
library(tidyverse)
library(tidytext)
library(igraph)
text_df <- example_text %>%
str_split('\\.') %>%
unlist() %>%
str_trim() %>%
str_to_lower() %>%
str_split(' ') %>%
map(function(x){
tibble(from = x[1:(length(x)-1)],
to = x[2:length(x)],
next_id = n())
})
library(tidyverse)
library(tidytext)
library(igraph)
text_df <- example_text %>%
str_split('\\.') %>%
unlist() %>%
str_trim() %>%
str_to_lower() %>%
str_split(' ') %>%
map(function(x){
tibble(from = x[1:(length(x)-1)],
to = x[2:length(x)],
next_id = 1:(length(x)-1))
})
text_df
text_df %>% enframe()
text_df %>% enframe(name = sentence_id)
text_df %>% enframe(name = "sentence_id")
text_df %>% enframe(name = "sentence_id") %>% unnest
text_df %>% enframe(name = "sentence_id") %>% unnest %>% tail
SnowballC::wordStem(text_df)
SnowballC::wordStem(text_df$to)
text_df
library(tidyverse)
library(SnowballC)
library(igraph)
text_df <- example_text %>%
str_split('\\.') %>%
unlist() %>%
str_trim() %>%
str_to_lower() %>%
str_split(' ') %>%
map(function(x){
tibble(from = x[1:(length(x)-1)],
to = x[2:length(x)],
next_id = 1:(length(x)-1))
}) %>%
enframe(name = 'sentence_id') %>%
unnest() %>%
filter() %>%
select(from, to, sentence_id, next_id) %>%
filter(to != '',
from != '')
SnowballC::wordStem(text_df$to)
text_df %>%
mutate(from = wordStem(from),
to = wordStem(to)) %>%
graph_from_data_frame() %>%
plot()
sapply(c('tidyverse', 'pdftools', 'igraph', 'NLP','openNLP'), library, character.only = T)
setwd('traversing_graphs_in_R/')
toc <- pdf_toc('useR! Abstracts/useR2016.pdf')
title_info <- lapply(1:length(toc$children), function(i){
talk_type = toc$children[[i]]$title
talk_children = toc$children[[i]]$children
lapply(1:length(talk_children), function(j){
talk_title <- talk_children[[j]]$title
talk_page <- switch(talk_type, "Poster" = ifelse(26 + j < 45, 26 + j, 26 + j + 1), "Lightning Talk" = ifelse(j+88 <106, j+88, j+89),  "Oral Presentation" = 134 + j)
tibble(talk_type = talk_type,
talk_title = talk_title,
talk_page = talk_page)
}) %>%
bind_rows
}) %>%
bind_rows %>%
mutate(talk_page = as.integer(talk_page)) %>%
mutate(talk_body = text[talk_page] %>%
str_replace('^[^\\n]*\\n', '')) %>%
mutate(talk_keywords = talk_body %>%
str_replace_all('\\n',' ') %>%
str_extract('(?<=Keywords:).+(?=\\s\\d{2,3}\\s$)'))
title_info <- lapply(1:length(toc$children), function(i){
talk_type = toc$children[[i]]$title
talk_children = toc$children[[i]]$children
lapply(1:length(talk_children), function(j){
talk_title <- talk_children[[j]]$title
talk_page <- switch(talk_type, "Poster" = ifelse(26 + j < 45, 26 + j, 26 + j + 1), "Lightning Talk" = ifelse(j+88 <106, j+88, j+89),  "Oral Presentation" = 134 + j)
tibble(talk_type = talk_type,
talk_title = talk_title,
talk_page = talk_page)
}) %>%
bind_rows
}) %>%
bind_rows %>%
mutate(talk_page = as.integer(talk_page)) %>%
mutate(talk_body = text[talk_page] %>%
str_replace('^[^\\n]*\\n', '')) %>%
mutate(talk_keywords = talk_body %>%
str_replace_all('\\n',' ') %>%
str_extract('(?<=Keywords:).+(?=\\s\\d{2,3}\\s$)'))
title_info <- lapply(1:length(toc$children), function(i){
talk_type = toc$children[[i]]$title
talk_children = toc$children[[i]]$children
lapply(1:length(talk_children), function(j){
talk_title <- talk_children[[j]]$title
talk_page <- switch(talk_type, "Poster" = ifelse(26 + j < 45, 26 + j, 26 + j + 1), "Lightning Talk" = ifelse(j+88 <106, j+88, j+89),  "Oral Presentation" = 134 + j)
tibble(talk_type = talk_type,
talk_title = talk_title,
talk_page = talk_page)
}) %>%
bind_rows
}) %>%
bind_rows
title_info
V(g2016)
g2016 <- read_graph('traversing_graphs_in_R/Data/g2016.graphml', 'graphml')
dir
dir()
g2016 <- read_graph('Data/g2016.graphml')
g2016 <- read_graph('Data/g2016.graphml', 'graphml')
test <- g2016  %>%
(function(x){
set_vertex_attr(x,
'abstract',
V(x)[type == 'ABSTRACT'],
V(x)[type == 'ABSTRACT']$pageBody  %>%
str_extract('(?<=Abstract:).+(?=Keywords:)') %>%
str_trim() %>%
str_replace_all('(?<=\\w)- (?=\\w)', ''))
})
test <- g2016  %>%
(function(x){
set_vertex_attr(x,
'abstract',
V(x)[nodeType == 'ABSTRACT'],
V(x)[nodeType == 'ABSTRACT']$pageBody  %>%
str_extract('(?<=Abstract:).+(?=Keywords:)') %>%
str_trim() %>%
str_replace_all('(?<=\\w)- (?=\\w)', ''))
})
test
V(test)$abstract
V(test)$abstract %>% .[!is.na(.)]
write_graph('Data/g2016_abstract.graphml', 'graphml')
write_graph(test, 'Data/g2016_abstract.graphml', 'graphml')
test
?openNLP::Maxent_POS_Tag_Annotator
g2016
g2016 <- read_graph('../Data/g2016_abstract.graphml', 'graphml')
dir
dir()
g2016 <- read_graph('Data/g2016_abstract.graphml', 'graphml')
g2016
g2016 %>%
V(g2016)[nodeType == 'ABSTRACT'] %>%
.$abstract %>%
str_replace_all('(?<=\\w)- (?=\\w)', '') %>%
map(function(x){
s <- as.String(x)
a <- annotate(s , list(sent_token_annotator, word_token_annotator, pos_tag_annotator)) %>%
{annotations_in_spans(subset(., type == 'word'),
subset(., type == 'sentence'))}
})
g2016 %>%
V() %>%
.[nodeType == 'ABSTRACT'] %>%
.$abstract %>%
str_replace_all('(?<=\\w)- (?=\\w)', '') %>%
map(function(x){
s <- as.String(x)
a <- annotate(s , list(sent_token_annotator, word_token_annotator, pos_tag_annotator)) %>%
{annotations_in_spans(subset(., type == 'word'),
subset(., type == 'sentence'))}
})
library(openNLP)
library(NLP)
sent_token_annotator <- Maxent_Sent_Token_Annotator()
word_token_annotator <- Maxent_Word_Token_Annotator()
pos_tag_annotator <- Maxent_POS_Tag_Annotator()
annotated_example <- example_text %>%
as.String() %>%
annotate(list(sent_token_annotator,
word_token_annotator,
pos_tag_annotator)) %>%
{
annotations_in_spans(subset(., type == 'word'),
subset(., type == 'sentence'))
}
abstracts <- g2016 %>%
V() %>%
.[nodeType == 'ABSTRACT'] %>%
.$abstract %>%
str_replace_all('(?<=\\w)- (?=\\w)', '') %>%
map(function(x){
s <- as.String(x)
a <- annotate(s , list(sent_token_annotator, word_token_annotator, pos_tag_annotator)) %>%
{annotations_in_spans(subset(., type == 'word'),
subset(., type == 'sentence'))}
})
abstracts
abstracts[[1]]
s <- V(g2016)[nodeType == 'ABSTRACT']$pageBody[[index]] %>%
str_extract('(?<=Abstract:).+(?=Keywords:)') %>%
str_trim() %>%
str_replace_all('(?<=\\w)- (?=\\w)', '') %>%
as.String()
s <- V(g2016)[nodeType == 'ABSTRACT']$abstract %>%
as.String()
s
s[1]
s <- V(g2016)[nodeType == 'ABSTRACT']$abstract %>%
map(as.String)
s
s[1]
s[10]
s[100]
s[[1]]
s[[1]][[abstract[[1]]]]
abstracts[[1]]
s[[1]][abstracts[[1]]]
example_text %>% as.String()
example_text %>%
as.String() %>%
.[annotated_example]
abstracts[[index]] %>%
map(function(x){
sapply(x, function(y){
original <- s[y] %>%
str_to_upper()
pos <- y$features[[1]]$POS
str_c(pos, ':', original)
}) %>%
c('BEGIN_SENT', ., 'END_SENT') %>%
{
tibble(from = .[1:(length(.)-1)],
to = .[2:length(.)])
} %>%
mutate(order = 1:nrow(.),
type = 'next')
}) %>%
enframe(name = 'sentence') %>%
unnest() %>%
select(from, to, sentence, order, type)
index
index= 2
abstracts[[index]] %>%
map(function(x){
sapply(x, function(y){
original <- s[y] %>%
str_to_upper()
pos <- y$features[[1]]$POS
str_c(pos, ':', original)
}) %>%
c('BEGIN_SENT', ., 'END_SENT') %>%
{
tibble(from = .[1:(length(.)-1)],
to = .[2:length(.)])
} %>%
mutate(order = 1:nrow(.),
type = 'next')
}) %>%
enframe(name = 'sentence') %>%
unnest() %>%
select(from, to, sentence, order, type)
abstracts[[index]] %>%
map(function(x){
sapply(x, function(y){
original <- s[[y]] %>%
str_to_upper()
pos <- y$features[[1]]$POS
str_c(pos, ':', original)
}) %>%
c('BEGIN_SENT', ., 'END_SENT') %>%
{
tibble(from = .[1:(length(.)-1)],
to = .[2:length(.)])
} %>%
mutate(order = 1:nrow(.),
type = 'next')
}) %>%
enframe(name = 'sentence') %>%
unnest() %>%
select(from, to, sentence, order, type)
abstracts[[1]]
abstracts[[1]][1]
abstracts[[index]] %>%
map(function(x){
sapply(x, function(y){
original <- s[[index]][y] %>%
str_to_upper()
pos <- y$features[[1]]$POS
str_c(pos, ':', original)
}) %>%
c('BEGIN_SENT', ., 'END_SENT') %>%
{
tibble(from = .[1:(length(.)-1)],
to = .[2:length(.)])
} %>%
mutate(order = 1:nrow(.),
type = 'next')
}) %>%
enframe(name = 'sentence') %>%
unnest() %>%
select(from, to, sentence, order, type)
g2016 %>%
V %>%
.[nodeType == 'ABSTRACT'] %>%
.$pageBody %>% .[2] %>%
str_extract('Keywords:.+(?!\\d\\d $))
g2016 %>%
V %>%
.[nodeType == 'ABSTRACT'] %>%
.$pageBody %>% .[2] %>%
str_extract('Keywords:.+(?!\\d\\d $)')
g2016 %>%
V %>%
.[nodeType == 'ABSTRACT'] %>%
.$pageBody %>%
.[2] %>%
str_trim %>%
str_extract('Keywords:.+(?!\\d\\d$)')
g2016 %>%
V %>%
.[nodeType == 'ABSTRACT'] %>%
.$pageBody %>%
.[2] %>%
str_trim %>%
str_extract('Keywords:.+(?=\\d\\d$)')
g2016 %>%
V %>%
.[nodeType == 'ABSTRACT'] %>%
.$pageBody %>%
.[2] %>%
str_trim %>%
str_extract('Keywords:.+(?=\\d\\d$)') %>%
str_trim() %>%
str_replace('- ', '')
ego(starwars_g, 1, V(starwars_g)[str_detect(name, 'Darth Vader)])
ego(starwars_g, 1, V(starwars_g)[str_detect(name, 'Darth Vader')])
ego(starwars_g, 1, V(starwars_g)[str_detect(name, 'Darth Vader')])
